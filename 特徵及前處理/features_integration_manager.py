#!/usr/bin/env python3
"""
Features ç›®éŒ„çµ±ä¸€æ•´åˆç®¡ç†å™¨
è² è²¬æª¢æŸ¥ã€é©—è­‰å’Œç®¡ç†æ‰€æœ‰æ¨¡æ…‹çš„ç‰¹å¾µæª”æ¡ˆ
"""

import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import pandas as pd

class FeaturesIntegrationManager:
    """çµ±ä¸€ç®¡ç†æ‰€æœ‰æ¨¡æ…‹ç‰¹å¾µçš„æ•´åˆå™¨"""

    def __init__(self, features_root: str = "features"):
        self.features_root = Path(features_root)
        self.vocabulary = [
            'again', 'bird', 'book', 'computer', 'cousin', 'deaf', 'drink', 'eat',
            'finish', 'fish', 'friend', 'good', 'happy', 'learn', 'like', 'mother',
            'need', 'nice', 'no', 'orange', 'school', 'sister', 'student', 'table',
            'teacher', 'tired', 'want', 'what', 'white', 'yes'
        ]

        # ç‰¹å¾µç›®éŒ„çµæ§‹
        self.feature_dirs = {
            'audio': self.features_root / 'audio_features',
            'visual_mediapipe': self.features_root / 'mediapipe_features',
            'visual_optical_flow': self.features_root / 'optical_flow_features',
            'text_embeddings': self.features_root / 'text_embeddings',
            'semantic': self.features_root / 'semantic_features'
        }

    def check_directory_structure(self) -> Dict[str, bool]:
        """æª¢æŸ¥æ‰€æœ‰ç‰¹å¾µç›®éŒ„æ˜¯å¦å­˜åœ¨"""
        structure_status = {}

        print("ğŸ” æª¢æŸ¥ features ç›®éŒ„çµæ§‹...")
        for modality, path in self.feature_dirs.items():
            exists = path.exists()
            structure_status[modality] = exists
            status = "âœ…" if exists else "âŒ"
            print(f"   {status} {modality}: {path}")

        return structure_status

    def analyze_audio_features(self) -> Dict[str, Dict[str, bool]]:
        """åˆ†æéŸ³è¨Šç‰¹å¾µå®Œæ•´æ€§"""
        print("\nğŸ¤ åˆ†æéŸ³è¨Šç‰¹å¾µ...")
        audio_status = {}

        audio_types = [
            'audio_features.json',
            'max_fusion_24d.npy',
            'mean_fusion_24d.npy',
            'normalized_24d.npy',
            'std_across_versions_24d.npy',
            'weighted_fusion_24d.npy'
        ]

        for word in self.vocabulary:
            word_status = {}
            for audio_type in audio_types:
                file_path = self.feature_dirs['audio'] / f"{word}_{audio_type}"
                exists = file_path.exists()
                word_status[audio_type] = exists

            audio_status[word] = word_status

        # çµ±è¨ˆå®Œæ•´æ€§
        complete_count = sum(1 for word_data in audio_status.values()
                           if all(word_data.values()))
        print(f"   ğŸ“Š éŸ³è¨Šç‰¹å¾µå®Œæ•´åº¦: {complete_count}/{len(self.vocabulary)} è©å½™")

        return audio_status

    def analyze_visual_features(self) -> Dict[str, Dict[str, any]]:
        """åˆ†æè¦–è¦ºç‰¹å¾µå®Œæ•´æ€§"""
        print("\nğŸ‘ï¸ åˆ†æè¦–è¦ºç‰¹å¾µ...")
        visual_status = {}

        # MediaPipe ç‰¹å¾µ
        mediapipe_status = {}
        for word in self.vocabulary:
            word_dir = self.feature_dirs['visual_mediapipe'] / word
            if word_dir.exists():
                npy_files = list(word_dir.glob("*.npy"))
                mediapipe_status[word] = {
                    'exists': True,
                    'file_count': len(npy_files),
                    'files': [f.name for f in npy_files[:5]]  # å‰5å€‹æª”æ¡ˆ
                }
            else:
                mediapipe_status[word] = {'exists': False, 'file_count': 0}

        # å…‰æµç‰¹å¾µ
        optical_flow_status = {}
        for word in self.vocabulary:
            word_dir = self.feature_dirs['visual_optical_flow'] / word
            if word_dir.exists():
                npy_files = list(word_dir.glob("*.npy"))
                optical_flow_status[word] = {
                    'exists': True,
                    'file_count': len(npy_files)
                }
            else:
                optical_flow_status[word] = {'exists': False, 'file_count': 0}

        visual_status['mediapipe'] = mediapipe_status
        visual_status['optical_flow'] = optical_flow_status

        # çµ±è¨ˆ
        mp_complete = sum(1 for data in mediapipe_status.values() if data['exists'])
        of_complete = sum(1 for data in optical_flow_status.values() if data['exists'])

        print(f"   ğŸ“Š MediaPipe ç‰¹å¾µ: {mp_complete}/{len(self.vocabulary)} è©å½™")
        print(f"   ğŸ“Š å…‰æµç‰¹å¾µ: {of_complete}/{len(self.vocabulary)} è©å½™")

        return visual_status

    def analyze_text_features(self) -> Dict[str, bool]:
        """åˆ†ææ–‡å­—ç‰¹å¾µå®Œæ•´æ€§"""
        print("\nğŸ“ åˆ†ææ–‡å­—ç‰¹å¾µ...")
        text_status = {}

        expected_files = [
            'word2vec_embeddings.npy',
            'fasttext_embeddings.npy',
            'bert_embeddings.npy',
            'unified_embeddings.npy'
        ]

        for file_name in expected_files:
            file_path = self.feature_dirs['text_embeddings'] / file_name
            exists = file_path.exists()
            text_status[file_name] = exists

            if exists:
                try:
                    data = np.load(file_path)
                    print(f"   âœ… {file_name}: {data.shape}")
                except Exception as e:
                    print(f"   âŒ {file_name}: è¼‰å…¥å¤±æ•— - {e}")
            else:
                print(f"   âŒ {file_name}: æª”æ¡ˆä¸å­˜åœ¨")

        return text_status

    def analyze_semantic_features(self) -> Dict[str, bool]:
        """åˆ†æèªç¾©ç‰¹å¾µå®Œæ•´æ€§"""
        print("\nğŸ§  åˆ†æèªç¾©ç‰¹å¾µ...")
        semantic_status = {}

        expected_files = [
            'semantic_analysis.json',
            'semantic_analysis_fixed.json',
            'semantic_analysis.json.backup'
        ]

        for file_name in expected_files:
            file_path = self.feature_dirs['semantic'] / file_name
            exists = file_path.exists()
            semantic_status[file_name] = exists

            if exists and file_name.endswith('.json'):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    print(f"   âœ… {file_name}: åŒ…å« {len(data)} å€‹éµ")
                except Exception as e:
                    print(f"   âŒ {file_name}: JSON è§£æå¤±æ•— - {e}")
            else:
                status = "âœ…" if exists else "âŒ"
                print(f"   {status} {file_name}")

        return semantic_status

    def generate_integration_report(self) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„æ•´åˆå ±å‘Š"""
        print("ğŸ”§ ç”Ÿæˆ Features æ•´åˆå ±å‘Š...")
        print("=" * 60)

        report = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'vocabulary_count': len(self.vocabulary),
            'vocabulary': self.vocabulary
        }

        # æª¢æŸ¥ç›®éŒ„çµæ§‹
        report['directory_structure'] = self.check_directory_structure()

        # åˆ†æå„æ¨¡æ…‹ç‰¹å¾µ
        report['audio_features'] = self.analyze_audio_features()
        report['visual_features'] = self.analyze_visual_features()
        report['text_features'] = self.analyze_text_features()
        report['semantic_features'] = self.analyze_semantic_features()

        return report

    def create_trimodal_mapping(self) -> Dict[str, Dict]:
        """å‰µå»ºä¸‰æ¨¡æ…‹å°æ‡‰é—œä¿‚"""
        print("\nğŸ”— å‰µå»ºä¸‰æ¨¡æ…‹å°æ‡‰é—œä¿‚...")

        trimodal_mapping = {}

        for word in self.vocabulary:
            mapping = {
                'word': word,
                'modalities': {
                    'visual': {
                        'mediapipe_dir': str(self.feature_dirs['visual_mediapipe'] / word),
                        'optical_flow_dir': str(self.feature_dirs['visual_optical_flow'] / word),
                        'available': (self.feature_dirs['visual_mediapipe'] / word).exists()
                    },
                    'audio': {
                        'features_json': str(self.feature_dirs['audio'] / f"{word}_audio_features.json"),
                        'fusion_variants': [
                            str(self.feature_dirs['audio'] / f"{word}_max_fusion_24d.npy"),
                            str(self.feature_dirs['audio'] / f"{word}_mean_fusion_24d.npy"),
                            str(self.feature_dirs['audio'] / f"{word}_normalized_24d.npy"),
                            str(self.feature_dirs['audio'] / f"{word}_weighted_fusion_24d.npy")
                        ],
                        'available': (self.feature_dirs['audio'] / f"{word}_audio_features.json").exists()
                    },
                    'text': {
                        'embeddings_dir': str(self.feature_dirs['text_embeddings']),
                        'semantic_file': str(self.feature_dirs['semantic'] / 'semantic_analysis_fixed.json'),
                        'available': (self.feature_dirs['text_embeddings'] / 'unified_embeddings.npy').exists()
                    }
                },
                'cross_modal_links': {
                    'visual_audio_alignment': f"video_{word} â†” audio_{word}",
                    'visual_text_mapping': f"video_{word} â†” text_{word}",
                    'audio_text_correspondence': f"audio_{word} â†” text_{word}",
                    'trimodal_fusion': f"video_{word} + audio_{word} + text_{word}"
                }
            }

            trimodal_mapping[word] = mapping

        return trimodal_mapping

    def save_integration_results(self, report: Dict, mapping: Dict) -> None:
        """ä¿å­˜æ•´åˆçµæœ"""
        # ä¿å­˜å ±å‘Š
        report_path = self.features_root / 'integration_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ æ•´åˆå ±å‘Šå·²ä¿å­˜: {report_path}")

        # ä¿å­˜ä¸‰æ¨¡æ…‹å°æ‡‰é—œä¿‚
        mapping_path = self.features_root / 'trimodal_mapping.json'
        with open(mapping_path, 'w', encoding='utf-8') as f:
            json.dump(mapping, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ ä¸‰æ¨¡æ…‹å°æ‡‰é—œä¿‚å·²ä¿å­˜: {mapping_path}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ Features ç›®éŒ„çµ±ä¸€æ•´åˆç®¡ç†å™¨")
    print("=" * 60)

    # åˆå§‹åŒ–ç®¡ç†å™¨
    manager = FeaturesIntegrationManager()

    # ç”Ÿæˆæ•´åˆå ±å‘Š
    report = manager.generate_integration_report()

    # å‰µå»ºä¸‰æ¨¡æ…‹å°æ‡‰é—œä¿‚
    trimodal_mapping = manager.create_trimodal_mapping()

    # ä¿å­˜çµæœ
    manager.save_integration_results(report, trimodal_mapping)

    print("\nâœ… Features æ•´åˆç®¡ç†å®Œæˆ!")
    print("   ğŸ“Š å¯æŸ¥çœ‹ features/integration_report.json")
    print("   ğŸ”— å¯æŸ¥çœ‹ features/trimodal_mapping.json")

if __name__ == "__main__":
    main()