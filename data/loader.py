"""
Data Loaders for Multi-Modal Sign Language Dataset
å¤šæ¨¡æ…‹æ‰‹èªæ•¸æ“šè¼‰å…¥å™¨
"""

import torch
from torch.utils.data import DataLoader, random_split
from typing import Dict, List, Tuple, Optional, Any
import numpy as np

from .dataset import TriModalDataset, SemanticBalancedSampler


def collate_multimodal_batch(batch: List[Tuple[Dict[str, torch.Tensor], int]]) -> Tuple[Dict[str, torch.Tensor], torch.Tensor]:
    """
    å¤šæ¨¡æ…‹æ‰¹æ¬¡æ•´ç†å‡½æ•¸

    Args:
        batch: æ‰¹æ¬¡æ•¸æ“šåˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ ç‚º (features_dict, label)

    Returns:
        batched_features: æ‰¹æ¬¡ç‰¹å¾µå­—å…¸
        batched_labels: æ‰¹æ¬¡æ¨™ç±¤å¼µé‡
    """
    # åˆ†é›¢ç‰¹å¾µå’Œæ¨™ç±¤
    features_list = [item[0] for item in batch]
    labels_list = [item[1] for item in batch]

    # ç²å–æ‰€æœ‰å¯èƒ½çš„æ¨¡æ…‹
    all_modalities = set()
    for features in features_list:
        all_modalities.update(features.keys())

    # ç‚ºæ¯å€‹æ¨¡æ…‹æ§‹å»ºæ‰¹æ¬¡å¼µé‡
    batched_features = {}

    for modality in all_modalities:
        # æ”¶é›†è©²æ¨¡æ…‹çš„æ‰€æœ‰ç‰¹å¾µ
        modality_features = []
        for features in features_list:
            if modality in features:
                modality_features.append(features[modality])
            else:
                # å¦‚æœæŸå€‹æ¨£æœ¬ç¼ºå°‘è©²æ¨¡æ…‹ï¼Œä½¿ç”¨é›¶å¼µé‡å¡«å……
                if modality == 'visual':
                    modality_features.append(torch.zeros(100, 417))
                elif modality == 'audio':
                    modality_features.append(torch.zeros(24))
                elif modality == 'text':
                    modality_features.append(torch.zeros(300))  # é»˜èªunifiedç¶­åº¦

        # å †ç–Šæˆæ‰¹æ¬¡å¼µé‡
        try:
            batched_features[modality] = torch.stack(modality_features, dim=0)
        except RuntimeError as e:
            print(f"Error stacking {modality} features: {e}")
            # æ‰“å°ç¶­åº¦ä¿¡æ¯ä»¥ä¾¿èª¿è©¦
            shapes = [f.shape for f in modality_features]
            print(f"Feature shapes: {shapes}")
            raise

    # æ§‹å»ºæ¨™ç±¤å¼µé‡
    batched_labels = torch.LongTensor(labels_list)

    return batched_features, batched_labels


def create_data_loaders(
    mapping_file: str = "features/trimodal_mapping.json",
    modalities: List[str] = ['visual', 'audio', 'text'],
    batch_size: int = 32,
    num_workers: int = 4,
    train_val_split: float = 0.8,
    text_embedding_type: str = 'unified',
    use_semantic_sampling: bool = False,
    visual_augment: bool = True,
    audio_dropout: float = 0.1,
    max_samples_per_word: Optional[int] = None,
    pin_memory: bool = True
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    å‰µå»ºè¨“ç·´ã€é©—è­‰ã€æ¸¬è©¦æ•¸æ“šè¼‰å…¥å™¨

    Args:
        mapping_file: ä¸‰æ¨¡æ…‹æ˜ å°„æ–‡ä»¶è·¯å¾‘
        modalities: ä½¿ç”¨çš„æ¨¡æ…‹åˆ—è¡¨
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: æ•¸æ“šè¼‰å…¥é€²ç¨‹æ•¸
        train_val_split: è¨“ç·´é›†æ¯”ä¾‹ (å‰©é¤˜ç‚ºé©—è­‰é›†)
        text_embedding_type: æ–‡å­—åµŒå…¥é¡å‹
        use_semantic_sampling: æ˜¯å¦ä½¿ç”¨èªç¾©å¹³è¡¡æ¡æ¨£
        visual_augment: æ˜¯å¦ä½¿ç”¨è¦–è¦ºæ•¸æ“šå¢å¼·
        audio_dropout: éŸ³è¨Šdropoutæ¯”ä¾‹
        max_samples_per_word: æ¯å€‹è©å½™æœ€å¤§æ¨£æœ¬æ•¸
        pin_memory: æ˜¯å¦ä½¿ç”¨pin memoryå„ªåŒ–

    Returns:
        train_loader, val_loader, test_loader
    """

    # å‰µå»ºæ•¸æ“šé›†
    train_dataset = TriModalDataset(
        mapping_file=mapping_file,
        mode='train',
        modalities=modalities,
        visual_augment=visual_augment,
        audio_dropout=audio_dropout,
        text_embedding_type=text_embedding_type,
        semantic_sampling=use_semantic_sampling,
        max_samples_per_word=max_samples_per_word
    )

    val_dataset = TriModalDataset(
        mapping_file=mapping_file,
        mode='val',
        modalities=modalities,
        visual_augment=False,  # é©—è­‰é›†ä¸ä½¿ç”¨æ•¸æ“šå¢å¼·
        audio_dropout=0.0,
        text_embedding_type=text_embedding_type,
        semantic_sampling=use_semantic_sampling,
        max_samples_per_word=max_samples_per_word
    )

    test_dataset = TriModalDataset(
        mapping_file=mapping_file,
        mode='test',
        modalities=modalities,
        visual_augment=False,  # æ¸¬è©¦é›†ä¸ä½¿ç”¨æ•¸æ“šå¢å¼·
        audio_dropout=0.0,
        text_embedding_type=text_embedding_type,
        semantic_sampling=use_semantic_sampling,
        max_samples_per_word=max_samples_per_word
    )

    # æ‰“å°æ•¸æ“šé›†çµ±è¨ˆè³‡è¨Š
    print("\nğŸ“Š æ•¸æ“šé›†çµ±è¨ˆ:")
    for dataset, name in [(train_dataset, 'Train'), (val_dataset, 'Val'), (test_dataset, 'Test')]:
        stats = dataset.get_statistics()
        print(f"{name:>5}: {stats['total_samples']:>5} æ¨£æœ¬, "
              f"å¹³å‡æ¯è© {stats['avg_samples_per_word']:.1f} æ¨£æœ¬")

    # å‰µå»ºæ•¸æ“šè¼‰å…¥å™¨
    common_loader_args = {
        'batch_size': batch_size,
        'num_workers': num_workers,
        'collate_fn': collate_multimodal_batch,
        'pin_memory': pin_memory and torch.cuda.is_available()
    }

    # è¨“ç·´é›†è¼‰å…¥å™¨
    if use_semantic_sampling and train_dataset.semantic_sampling:
        # ä½¿ç”¨èªç¾©å¹³è¡¡æ¡æ¨£å™¨
        semantic_sampler = SemanticBalancedSampler(train_dataset, batch_size)
        train_loader = DataLoader(
            train_dataset,
            batch_sampler=semantic_sampler,
            **{k: v for k, v in common_loader_args.items() if k != 'batch_size'}
        )
    else:
        # ä½¿ç”¨éš¨æ©Ÿæ¡æ¨£
        train_loader = DataLoader(
            train_dataset,
            shuffle=True,
            **common_loader_args
        )

    # é©—è­‰é›†å’Œæ¸¬è©¦é›†è¼‰å…¥å™¨ (ä¸ä½¿ç”¨ç‰¹æ®Šæ¡æ¨£)
    val_loader = DataLoader(
        val_dataset,
        shuffle=False,
        **common_loader_args
    )

    test_loader = DataLoader(
        test_dataset,
        shuffle=False,
        **common_loader_args
    )

    return train_loader, val_loader, test_loader


def create_single_modal_loaders(
    modality: str,
    mapping_file: str = "features/trimodal_mapping.json",
    batch_size: int = 32,
    num_workers: int = 4,
    **kwargs
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    å‰µå»ºå–®æ¨¡æ…‹æ•¸æ“šè¼‰å…¥å™¨ (ç”¨æ–¼éšæ®µ1è¨“ç·´)

    Args:
        modality: å–®ä¸€æ¨¡æ…‹åç¨± ('visual', 'audio', 'text')
        å…¶ä»–åƒæ•¸åŒ create_data_loaders

    Returns:
        train_loader, val_loader, test_loader (åƒ…åŒ…å«æŒ‡å®šæ¨¡æ…‹)
    """
    return create_data_loaders(
        mapping_file=mapping_file,
        modalities=[modality],
        batch_size=batch_size,
        num_workers=num_workers,
        **kwargs
    )


def create_dual_modal_loaders(
    modality_pair: List[str],
    mapping_file: str = "features/trimodal_mapping.json",
    batch_size: int = 32,
    num_workers: int = 4,
    **kwargs
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    å‰µå»ºé›™æ¨¡æ…‹æ•¸æ“šè¼‰å…¥å™¨ (ç”¨æ–¼éšæ®µ2è¨“ç·´)

    Args:
        modality_pair: æ¨¡æ…‹å°ï¼Œå¦‚ ['visual', 'audio']
        å…¶ä»–åƒæ•¸åŒ create_data_loaders

    Returns:
        train_loader, val_loader, test_loader (åƒ…åŒ…å«æŒ‡å®šæ¨¡æ…‹å°)
    """
    if len(modality_pair) != 2:
        raise ValueError("modality_pair must contain exactly 2 modalities")

    return create_data_loaders(
        mapping_file=mapping_file,
        modalities=modality_pair,
        batch_size=batch_size,
        num_workers=num_workers,
        **kwargs
    )


class DataLoaderFactory:
    """
    æ•¸æ“šè¼‰å…¥å™¨å·¥å» é¡
    ç°¡åŒ–ä¸åŒéšæ®µçš„æ•¸æ“šè¼‰å…¥å™¨å‰µå»º
    """

    def __init__(
        self,
        mapping_file: str = "features/trimodal_mapping.json",
        batch_size: int = 32,
        num_workers: int = 4,
        text_embedding_type: str = 'unified',
        **default_kwargs
    ):
        self.mapping_file = mapping_file
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.text_embedding_type = text_embedding_type
        self.default_kwargs = default_kwargs

    def stage1_loaders(self, modality: str) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """éšæ®µ1: å–®æ¨¡æ…‹è¨“ç·´è¼‰å…¥å™¨"""
        return create_single_modal_loaders(
            modality=modality,
            mapping_file=self.mapping_file,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            text_embedding_type=self.text_embedding_type,
            **self.default_kwargs
        )

    def stage2_loaders(self, modality_pair: List[str]) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """éšæ®µ2: é›™æ¨¡æ…‹è¨“ç·´è¼‰å…¥å™¨"""
        return create_dual_modal_loaders(
            modality_pair=modality_pair,
            mapping_file=self.mapping_file,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            text_embedding_type=self.text_embedding_type,
            **self.default_kwargs
        )

    def stage3_loaders(self) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """éšæ®µ3: ä¸‰æ¨¡æ…‹è¨“ç·´è¼‰å…¥å™¨"""
        return create_data_loaders(
            mapping_file=self.mapping_file,
            modalities=['visual', 'audio', 'text'],
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            text_embedding_type=self.text_embedding_type,
            **self.default_kwargs
        )


def test_data_loading():
    """
    æ¸¬è©¦æ•¸æ“šè¼‰å…¥åŠŸèƒ½
    ç”¨æ–¼é©—è­‰æ•¸æ“šè¼‰å…¥å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    print("ğŸ§ª æ¸¬è©¦æ•¸æ“šè¼‰å…¥å™¨...")

    try:
        # æ¸¬è©¦ä¸‰æ¨¡æ…‹è¼‰å…¥å™¨
        train_loader, val_loader, test_loader = create_data_loaders(
            batch_size=8,
            num_workers=0  # æ¸¬è©¦æ™‚ä½¿ç”¨å–®é€²ç¨‹
        )

        print("âœ… æ•¸æ“šè¼‰å…¥å™¨å‰µå»ºæˆåŠŸ")

        # æ¸¬è©¦æ‰¹æ¬¡è¼‰å…¥
        for i, (features, labels) in enumerate(train_loader):
            print(f"âœ… æ‰¹æ¬¡ {i+1}:")
            print(f"   æ¨™ç±¤å½¢ç‹€: {labels.shape}")

            for modality, feature_tensor in features.items():
                print(f"   {modality:>6} ç‰¹å¾µ: {feature_tensor.shape}")

            if i >= 2:  # åªæ¸¬è©¦å‰3å€‹æ‰¹æ¬¡
                break

        print("âœ… æ•¸æ“šè¼‰å…¥æ¸¬è©¦å®Œæˆ!")

    except Exception as e:
        print(f"âŒ æ•¸æ“šè¼‰å…¥æ¸¬è©¦å¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    test_data_loading()