"""
Progressive Multi-Modal Training Framework
ä¸‰éšæ®µæ¼¸é€²å¼å¤šæ¨¡æ…‹è¨“ç·´æ¡†æ¶
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple, Union
import time
import os
from pathlib import Path
import json

from models import MultiModalSignClassifier, create_multimodal_classifier
from .utils import EarlyStopping, ModelCheckpoint, TrainingLogger


class BaseTrainer:
    """åŸºç¤è¨“ç·´å™¨"""

    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        device: torch.device,
        learning_rate: float = 1e-4,
        weight_decay: float = 0.01,
        save_dir: str = "checkpoints"
    ):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)

        # å„ªåŒ–å™¨å’Œå­¸ç¿’ç‡èª¿åº¦å™¨
        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )

        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=50,
            eta_min=learning_rate * 0.01
        )

        # æå¤±å‡½æ•¸
        self.criterion = nn.CrossEntropyLoss()

        # è¨“ç·´å·¥å…·
        self.early_stopping = EarlyStopping(patience=10, min_delta=0.001)
        self.checkpoint = ModelCheckpoint(save_dir=save_dir)
        self.logger = TrainingLogger()

    def train_epoch(self) -> Tuple[float, float]:
        """è¨“ç·´ä¸€å€‹epoch"""
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (features, labels) in enumerate(self.train_loader):
            # ç§»å‹•æ•¸æ“šåˆ°è¨­å‚™
            for k in features:
                features[k] = features[k].to(self.device)
            labels = labels.to(self.device)

            # å‰å‘å‚³æ’­
            self.optimizer.zero_grad()
            outputs = self.model(features)
            loss = self.criterion(outputs, labels)

            # åå‘å‚³æ’­
            loss.backward()
            self.optimizer.step()

            # çµ±è¨ˆ
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        avg_loss = total_loss / len(self.train_loader)
        accuracy = correct / total
        return avg_loss, accuracy

    def validate(self) -> Tuple[float, float]:
        """é©—è­‰"""
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for features, labels in self.val_loader:
                # ç§»å‹•æ•¸æ“šåˆ°è¨­å‚™
                for k in features:
                    features[k] = features[k].to(self.device)
                labels = labels.to(self.device)

                # å‰å‘å‚³æ’­
                outputs = self.model(features)
                loss = self.criterion(outputs, labels)

                # çµ±è¨ˆ
                total_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

        avg_loss = total_loss / len(self.val_loader)
        accuracy = correct / total
        return avg_loss, accuracy

    def train(self, epochs: int, verbose: bool = True) -> Dict[str, List[float]]:
        """å®Œæ•´è¨“ç·´æµç¨‹"""
        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}

        for epoch in range(epochs):
            start_time = time.time()

            # è¨“ç·´
            train_loss, train_acc = self.train_epoch()

            # é©—è­‰
            val_loss, val_acc = self.validate()

            # å­¸ç¿’ç‡èª¿åº¦
            self.scheduler.step()

            # è¨˜éŒ„æ­·å²
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)

            # æ—¥èªŒè¨˜éŒ„
            epoch_time = time.time() - start_time
            if verbose:
                print(f"Epoch {epoch+1:3d}/{epochs}: "
                      f"Train Loss={train_loss:.4f}, Train Acc={train_acc:.3f}, "
                      f"Val Loss={val_loss:.4f}, Val Acc={val_acc:.3f}, "
                      f"Time={epoch_time:.1f}s")

            # æ—©åœæª¢æŸ¥
            if self.early_stopping(val_loss):
                print(f"Early stopping at epoch {epoch+1}")
                break

            # æ¨¡å‹æª¢æŸ¥é»
            is_best = self.checkpoint.update(val_acc, self.model, epoch)
            if is_best and verbose:
                print(f"ğŸ† New best model saved with val_acc={val_acc:.3f}")

        return history


class SingleModalTrainer(BaseTrainer):
    """
    å–®æ¨¡æ…‹è¨“ç·´å™¨
    ç”¨æ–¼Stage 1: å–®æ¨¡æ…‹é è¨“ç·´
    """

    def __init__(self, modality: str, **kwargs):
        self.modality = modality

        # å‰µå»ºå–®æ¨¡æ…‹æ¨¡å‹
        model = create_multimodal_classifier(
            modalities=[modality],
            **kwargs.pop('model_config', {})
        )

        super().__init__(model=model, **kwargs)

    def train_epoch(self) -> Tuple[float, float]:
        """å–®æ¨¡æ…‹è¨“ç·´ä¸€å€‹epoch"""
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (features, labels) in enumerate(self.train_loader):
            # ç§»å‹•æ•¸æ“šåˆ°è¨­å‚™ï¼Œåªä½¿ç”¨æŒ‡å®šæ¨¡æ…‹
            modal_features = {
                self.modality: features[self.modality].to(self.device)
            }
            labels = labels.to(self.device)

            # å‰å‘å‚³æ’­
            self.optimizer.zero_grad()
            outputs = self.model(modal_features)
            loss = self.criterion(outputs, labels)

            # åå‘å‚³æ’­
            loss.backward()
            self.optimizer.step()

            # çµ±è¨ˆ
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        avg_loss = total_loss / len(self.train_loader)
        accuracy = correct / total
        return avg_loss, accuracy


class DualModalTrainer(BaseTrainer):
    """
    é›™æ¨¡æ…‹è¨“ç·´å™¨
    ç”¨æ–¼Stage 2: é›™æ¨¡æ…‹å°é½Šå­¸ç¿’
    """

    def __init__(
        self,
        modality_pair: List[str],
        contrastive_weight: float = 0.1,
        **kwargs
    ):
        self.modality_pair = modality_pair
        self.contrastive_weight = contrastive_weight

        # å‰µå»ºé›™æ¨¡æ…‹æ¨¡å‹
        model = create_multimodal_classifier(
            modalities=modality_pair,
            use_contrastive_loss=True,
            **kwargs.pop('model_config', {})
        )

        super().__init__(model=model, **kwargs)

    def train_epoch(self) -> Tuple[float, float]:
        """é›™æ¨¡æ…‹è¨“ç·´ä¸€å€‹epochï¼ˆåŒ…å«å°æ¯”å­¸ç¿’ï¼‰"""
        self.model.train()
        total_loss = 0.0
        total_cls_loss = 0.0
        total_contrastive_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (features, labels) in enumerate(self.train_loader):
            # ç§»å‹•æ•¸æ“šåˆ°è¨­å‚™ï¼Œåªä½¿ç”¨æŒ‡å®šæ¨¡æ…‹å°
            modal_features = {}
            for modality in self.modality_pair:
                modal_features[modality] = features[modality].to(self.device)
            labels = labels.to(self.device)

            # å‰å‘å‚³æ’­
            self.optimizer.zero_grad()
            outputs, embeddings = self.model(
                modal_features,
                return_embeddings=True
            )

            # åˆ†é¡æå¤±
            cls_loss = self.criterion(outputs, labels)

            # å°æ¯”æå¤±
            contrastive_losses = self.model.compute_contrastive_loss(embeddings, labels)
            contrastive_loss = sum(contrastive_losses.values())

            # ç¸½æå¤±
            total_loss_batch = cls_loss + self.contrastive_weight * contrastive_loss

            # åå‘å‚³æ’­
            total_loss_batch.backward()
            self.optimizer.step()

            # çµ±è¨ˆ
            total_loss += total_loss_batch.item()
            total_cls_loss += cls_loss.item()
            total_contrastive_loss += contrastive_loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        avg_loss = total_loss / len(self.train_loader)
        avg_cls_loss = total_cls_loss / len(self.train_loader)
        avg_contrastive_loss = total_contrastive_loss / len(self.train_loader)
        accuracy = correct / total

        print(f"  åˆ†é¡æå¤±: {avg_cls_loss:.4f}, å°æ¯”æå¤±: {avg_contrastive_loss:.4f}")
        return avg_loss, accuracy


class TriModalTrainer(BaseTrainer):
    """
    ä¸‰æ¨¡æ…‹è¨“ç·´å™¨
    ç”¨æ–¼Stage 3: ä¸‰æ¨¡æ…‹èåˆè¨“ç·´
    """

    def __init__(
        self,
        contrastive_weight: float = 0.1,
        consistency_weight: float = 0.05,
        **kwargs
    ):
        self.contrastive_weight = contrastive_weight
        self.consistency_weight = consistency_weight

        # å‰µå»ºä¸‰æ¨¡æ…‹æ¨¡å‹
        model = create_multimodal_classifier(
            modalities=['visual', 'audio', 'text'],
            use_contrastive_loss=True,
            **kwargs.pop('model_config', {})
        )

        super().__init__(model=model, **kwargs)

    def train_epoch(self) -> Tuple[float, float]:
        """ä¸‰æ¨¡æ…‹è¨“ç·´ä¸€å€‹epochï¼ˆåŒ…å«å°æ¯”å­¸ç¿’å’Œä¸€è‡´æ€§æ­£å‰‡åŒ–ï¼‰"""
        self.model.train()
        total_loss = 0.0
        total_cls_loss = 0.0
        total_contrastive_loss = 0.0
        total_consistency_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (features, labels) in enumerate(self.train_loader):
            # ç§»å‹•æ•¸æ“šåˆ°è¨­å‚™
            for k in features:
                features[k] = features[k].to(self.device)
            labels = labels.to(self.device)

            # å‰å‘å‚³æ’­
            self.optimizer.zero_grad()
            outputs, embeddings, attention_weights = self.model(
                features,
                return_embeddings=True,
                return_attention_weights=True
            )

            # åˆ†é¡æå¤±
            cls_loss = self.criterion(outputs, labels)

            # å°æ¯”æå¤±
            contrastive_losses = self.model.compute_contrastive_loss(embeddings, labels)
            contrastive_loss = sum(contrastive_losses.values())

            # ä¸€è‡´æ€§æå¤±ï¼ˆæ¨¡æ…‹é–“é æ¸¬ä¸€è‡´æ€§ï¼‰
            consistency_loss = self._compute_consistency_loss(embeddings, labels)

            # ç¸½æå¤±
            total_loss_batch = (
                cls_loss +
                self.contrastive_weight * contrastive_loss +
                self.consistency_weight * consistency_loss
            )

            # åå‘å‚³æ’­
            total_loss_batch.backward()
            self.optimizer.step()

            # çµ±è¨ˆ
            total_loss += total_loss_batch.item()
            total_cls_loss += cls_loss.item()
            total_contrastive_loss += contrastive_loss.item()
            total_consistency_loss += consistency_loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        avg_loss = total_loss / len(self.train_loader)
        avg_cls_loss = total_cls_loss / len(self.train_loader)
        avg_contrastive_loss = total_contrastive_loss / len(self.train_loader)
        avg_consistency_loss = total_consistency_loss / len(self.train_loader)
        accuracy = correct / total

        print(f"  åˆ†é¡: {avg_cls_loss:.4f}, å°æ¯”: {avg_contrastive_loss:.4f}, ä¸€è‡´æ€§: {avg_consistency_loss:.4f}")
        return avg_loss, accuracy

    def _compute_consistency_loss(
        self,
        embeddings: Dict[str, torch.Tensor],
        labels: torch.Tensor
    ) -> torch.Tensor:
        """è¨ˆç®—æ¨¡æ…‹é–“ä¸€è‡´æ€§æå¤±"""
        # å‰µå»ºè‡¨æ™‚åˆ†é¡å™¨ä¾†æ¸¬è©¦å„æ¨¡æ…‹çš„é æ¸¬ä¸€è‡´æ€§
        temp_classifier = nn.Linear(512, self.model.num_classes).to(self.device)

        consistency_losses = []
        modal_predictions = {}

        # ç‚ºæ¯å€‹æ¨¡æ…‹è¨ˆç®—é æ¸¬
        for modality, emb in embeddings.items():
            modal_pred = temp_classifier(emb)
            modal_predictions[modality] = F.softmax(modal_pred, dim=-1)

        # è¨ˆç®—æ¨¡æ…‹é–“é æ¸¬çš„KLæ•£åº¦
        modalities = list(modal_predictions.keys())
        for i in range(len(modalities)):
            for j in range(i + 1, len(modalities)):
                pred_i = modal_predictions[modalities[i]]
                pred_j = modal_predictions[modalities[j]]

                # KLæ•£åº¦ï¼ˆé›™å‘ï¼‰
                kl_loss = F.kl_div(
                    pred_i.log(), pred_j, reduction='batchmean'
                ) + F.kl_div(
                    pred_j.log(), pred_i, reduction='batchmean'
                )
                consistency_losses.append(kl_loss)

        return torch.stack(consistency_losses).mean() if consistency_losses else torch.tensor(0.0)


class ProgressiveTrainer:
    """
    æ¼¸é€²å¼ä¸‰éšæ®µè¨“ç·´å”èª¿å™¨
    å”èª¿æ•´å€‹è¨“ç·´æµç¨‹
    """

    def __init__(
        self,
        data_loaders: Dict[str, DataLoader],
        device: torch.device,
        save_dir: str = "checkpoints",
        config: Optional[Dict] = None
    ):
        self.data_loaders = data_loaders
        self.device = device
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        self.config = config or {}

        # è¨“ç·´æ­·å²
        self.training_history = {
            'stage1': {},
            'stage2': {},
            'stage3': {}
        }

    def train_stage1(self, epochs: int = 15) -> Dict[str, Dict]:
        """éšæ®µ1: å–®æ¨¡æ…‹é è¨“ç·´"""
        print("ğŸš€ é–‹å§‹éšæ®µ1: å–®æ¨¡æ…‹é è¨“ç·´")
        stage1_history = {}

        for modality in ['visual', 'audio', 'text']:
            print(f"\nğŸ“Š è¨“ç·´ {modality.upper()} æ¨¡æ…‹...")

            # å‰µå»ºå–®æ¨¡æ…‹è¨“ç·´å™¨
            trainer = SingleModalTrainer(
                modality=modality,
                train_loader=self.data_loaders['train'],
                val_loader=self.data_loaders['val'],
                device=self.device,
                learning_rate=1e-4,
                save_dir=self.save_dir / f"stage1_{modality}"
            )

            # è¨“ç·´
            history = trainer.train(epochs=epochs)
            stage1_history[modality] = history

            # ä¿å­˜æ¨¡æ…‹ç·¨ç¢¼å™¨
            encoder_path = self.save_dir / f"stage1_{modality}_encoder.pth"
            torch.save(trainer.model.encoders[modality].state_dict(), encoder_path)
            print(f"âœ… ä¿å­˜ {modality} ç·¨ç¢¼å™¨: {encoder_path}")

        self.training_history['stage1'] = stage1_history
        return stage1_history

    def train_stage2(self, epochs: int = 20) -> Dict[str, Dict]:
        """éšæ®µ2: é›™æ¨¡æ…‹å°é½Šå­¸ç¿’"""
        print("\nğŸ”¥ é–‹å§‹éšæ®µ2: é›™æ¨¡æ…‹å°é½Šå­¸ç¿’")
        stage2_history = {}

        modal_pairs = [
            ['visual', 'audio'],
            ['visual', 'text'],
            ['audio', 'text']
        ]

        for pair in modal_pairs:
            pair_name = f"{pair[0]}_{pair[1]}"
            print(f"\nğŸ“Š è¨“ç·´ {pair[0].upper()} + {pair[1].upper()} èåˆ...")

            # å‰µå»ºé›™æ¨¡æ…‹è¨“ç·´å™¨
            trainer = DualModalTrainer(
                modality_pair=pair,
                train_loader=self.data_loaders['train'],
                val_loader=self.data_loaders['val'],
                device=self.device,
                learning_rate=5e-5,
                contrastive_weight=0.1,
                save_dir=self.save_dir / f"stage2_{pair_name}"
            )

            # è¼‰å…¥é è¨“ç·´ç·¨ç¢¼å™¨
            for modality in pair:
                encoder_path = self.save_dir / f"stage1_{modality}_encoder.pth"
                if encoder_path.exists():
                    state_dict = torch.load(encoder_path, map_location=self.device)
                    trainer.model.encoders[modality].load_state_dict(state_dict)
                    print(f"âœ… è¼‰å…¥é è¨“ç·´ {modality} ç·¨ç¢¼å™¨")

            # è¨“ç·´
            history = trainer.train(epochs=epochs)
            stage2_history[pair_name] = history

        self.training_history['stage2'] = stage2_history
        return stage2_history

    def train_stage3(self, epochs: int = 25) -> Dict[str, List[float]]:
        """éšæ®µ3: ä¸‰æ¨¡æ…‹èåˆè¨“ç·´"""
        print("\nâš¡ é–‹å§‹éšæ®µ3: ä¸‰æ¨¡æ…‹èåˆè¨“ç·´")

        # å‰µå»ºä¸‰æ¨¡æ…‹è¨“ç·´å™¨
        trainer = TriModalTrainer(
            train_loader=self.data_loaders['train'],
            val_loader=self.data_loaders['val'],
            device=self.device,
            learning_rate=1e-5,
            contrastive_weight=0.1,
            consistency_weight=0.05,
            save_dir=self.save_dir / "stage3_trimodal"
        )

        # è¼‰å…¥é è¨“ç·´ç·¨ç¢¼å™¨
        for modality in ['visual', 'audio', 'text']:
            encoder_path = self.save_dir / f"stage1_{modality}_encoder.pth"
            if encoder_path.exists():
                state_dict = torch.load(encoder_path, map_location=self.device)
                trainer.model.encoders[modality].load_state_dict(state_dict)
                print(f"âœ… è¼‰å…¥é è¨“ç·´ {modality} ç·¨ç¢¼å™¨")

        # è¨“ç·´
        history = trainer.train(epochs=epochs)

        # ä¿å­˜æœ€çµ‚æ¨¡å‹
        final_model_path = self.save_dir / "final_trimodal_model.pth"
        torch.save(trainer.model.state_dict(), final_model_path)
        print(f"ğŸ† ä¿å­˜æœ€çµ‚æ¨¡å‹: {final_model_path}")

        self.training_history['stage3'] = history
        return history

    def full_training_pipeline(
        self,
        stage1_epochs: int = 15,
        stage2_epochs: int = 20,
        stage3_epochs: int = 25
    ) -> Dict:
        """å®Œæ•´çš„ä¸‰éšæ®µè¨“ç·´æµç¨‹"""
        print("ğŸš€ é–‹å§‹å®Œæ•´ä¸‰éšæ®µæ¼¸é€²å¼è¨“ç·´...")

        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        start_time = time.time()

        # éšæ®µ1: å–®æ¨¡æ…‹é è¨“ç·´
        stage1_history = self.train_stage1(epochs=stage1_epochs)

        # éšæ®µ2: é›™æ¨¡æ…‹å°é½Šå­¸ç¿’
        stage2_history = self.train_stage2(epochs=stage2_epochs)

        # éšæ®µ3: ä¸‰æ¨¡æ…‹èåˆè¨“ç·´
        stage3_history = self.train_stage3(epochs=stage3_epochs)

        # ç¸½è¨“ç·´æ™‚é–“
        total_time = time.time() - start_time

        # ä¿å­˜è¨“ç·´æ­·å²
        history_file = self.save_dir / "training_history.json"
        with open(history_file, 'w') as f:
            json.dump(self.training_history, f, indent=2)

        print(f"\nğŸ‰ å®Œæ•´è¨“ç·´å®Œæˆï¼ç¸½æ™‚é–“: {total_time/3600:.1f} å°æ™‚")
        print(f"ğŸ“Š è¨“ç·´æ­·å²ä¿å­˜è‡³: {history_file}")

        return self.training_history


def test_training_pipeline():
    """æ¸¬è©¦è¨“ç·´æµç¨‹"""
    print("ğŸ§ª æ¸¬è©¦è¨“ç·´æµç¨‹...")

    # é€™è£¡åªæ˜¯å±•ç¤ºå¦‚ä½•ä½¿ç”¨ï¼Œå¯¦éš›éœ€è¦çœŸå¯¦çš„æ•¸æ“šè¼‰å…¥å™¨
    from data import create_data_loaders

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    try:
        # å‰µå»ºæ•¸æ“šè¼‰å…¥å™¨
        train_loader, val_loader, test_loader = create_data_loaders(
            batch_size=8,
            num_workers=0
        )

        data_loaders = {
            'train': train_loader,
            'val': val_loader,
            'test': test_loader
        }

        # å‰µå»ºæ¼¸é€²å¼è¨“ç·´å™¨
        progressive_trainer = ProgressiveTrainer(
            data_loaders=data_loaders,
            device=device,
            save_dir="test_checkpoints"
        )

        print("âœ… è¨“ç·´å™¨å‰µå»ºæˆåŠŸ")
        print("ğŸ’¡ è¦é–‹å§‹å®Œæ•´è¨“ç·´ï¼Œé‹è¡Œ: progressive_trainer.full_training_pipeline()")

    except Exception as e:
        print(f"âŒ è¨“ç·´æµç¨‹æ¸¬è©¦å¤±æ•—: {e}")


if __name__ == "__main__":
    test_training_pipeline()